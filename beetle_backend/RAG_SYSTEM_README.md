# Beetle RAG System - Complete Implementation

A comprehensive Retrieval-Augmented Generation (RAG) system with agentic workflows, built for coding-related queries and document processing.

## ğŸš€ Features

### Core RAG Capabilities
- **Intelligent Document Processing**: Multi-format document ingestion with semantic chunking
- **Advanced Vector Search**: Qdrant-based vector database with multiple embedding models
- **Multi-LLM Support**: OpenAI, Anthropic, and local model integration
- **Context-Aware Generation**: Intelligent prompt engineering and context building
- **Real-time Query Processing**: Fast retrieval and generation pipeline

### Agentic Workflows
- **Modular Agent Architecture**: Specialized agents for different tasks
- **Workflow Orchestration**: Configurable workflows for complex operations
- **Agent Collaboration**: Inter-agent communication and task delegation
- **Dynamic Task Scheduling**: Priority-based task execution
- **Error Handling & Recovery**: Robust error management and retry mechanisms

### Advanced Features
- **Performance Monitoring**: Real-time metrics and health monitoring
- **Caching System**: Redis-based caching for improved performance
- **Evaluation Framework**: Comprehensive evaluation and benchmarking
- **Security & Authentication**: Built-in security features
- **Scalable Architecture**: Designed for high-throughput applications

## ğŸ“ Project Structure

```
beetle_backend/src/ai/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ fastapi_server.py          # FastAPI server implementation
â”œâ”€â”€ pipeline_bridge.py         # Main pipeline orchestration
â”‚
â”œâ”€â”€ models/                    # Data models
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ document.py           # Document models
â”‚   â”œâ”€â”€ rag_models.py         # RAG-specific models
â”‚   â”œâ”€â”€ workflow_models.py    # Workflow orchestration models
â”‚   â””â”€â”€ agent_models.py       # Agent communication models
â”‚
â”œâ”€â”€ controllers/               # Business logic controllers
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ pipeline_controller.py # Main pipeline controller
â”‚   â”œâ”€â”€ rag_controller.py     # RAG operations controller
â”‚   â”œâ”€â”€ workflow_controller.py # Workflow management
â”‚   â””â”€â”€ agent_orchestrator.py # Agent orchestration
â”‚
â”œâ”€â”€ agents/                    # Agent implementations
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base_agent.py         # Base agent class
â”‚   â”‚
â”‚   â”œâ”€â”€ core/                 # Core RAG agents
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ document_processor.py
â”‚   â”‚   â”œâ”€â”€ chunking_agent.py
â”‚   â”‚   â”œâ”€â”€ embedding_agent.py
â”‚   â”‚   â”œâ”€â”€ retrieval_agent.py
â”‚   â”‚   â”œâ”€â”€ reranking_agent.py
â”‚   â”‚   â””â”€â”€ generation_agent.py
â”‚   â”‚
â”‚   â”œâ”€â”€ ingestion/            # Document ingestion agents
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ github_fetcher.py
â”‚   â”‚   â”œâ”€â”€ web_scraper.py
â”‚   â”‚   â”œâ”€â”€ file_ingestion_agent.py
â”‚   â”‚   â””â”€â”€ code_parser_agent.py
â”‚   â”‚
â”‚   â”œâ”€â”€ processing/           # Content processing agents
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ format_agent.py
â”‚   â”‚   â”œâ”€â”€ prompt_rewriter.py
â”‚   â”‚   â”œâ”€â”€ answering_agent.py
â”‚   â”‚   â”œâ”€â”€ code_analysis_agent.py
â”‚   â”‚   â””â”€â”€ context_builder_agent.py
â”‚   â”‚
â”‚   â”œâ”€â”€ workflow/             # Workflow agents
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ workflow_executor.py
â”‚   â”‚   â”œâ”€â”€ task_scheduler.py
â”‚   â”‚   â”œâ”€â”€ decision_agent.py
â”‚   â”‚   â””â”€â”€ collaboration_agent.py
â”‚   â”‚
â”‚   â””â”€â”€ specialized/          # Specialized agents
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ code_review_agent.py
â”‚       â”œâ”€â”€ documentation_agent.py
â”‚       â”œâ”€â”€ testing_agent.py
â”‚       â””â”€â”€ optimization_agent.py
â”‚
â”œâ”€â”€ services/                 # Core services
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ vector_store_service.py # Qdrant vector database service
â”‚   â”œâ”€â”€ llm_service.py        # LLM provider service
â”‚   â”œâ”€â”€ cache_service.py      # Redis caching service
â”‚   â”œâ”€â”€ monitoring_service.py # System monitoring
â”‚   â””â”€â”€ evaluation_service.py # Performance evaluation
â”‚
â”œâ”€â”€ workflows/                # Workflow definitions
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ rag_workflow.py       # RAG processing workflow
â”‚   â”œâ”€â”€ code_analysis_workflow.py
â”‚   â”œâ”€â”€ documentation_workflow.py
â”‚   â””â”€â”€ review_workflow.py
â”‚
â”œâ”€â”€ utils/                    # Utility functions
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ code_utils.py         # Code processing utilities
â”‚   â”œâ”€â”€ text_utils.py         # Text processing utilities
â”‚   â”œâ”€â”€ embedding_utils.py    # Embedding operations
â”‚   â”œâ”€â”€ prompt_utils.py       # Prompt management
â”‚   â””â”€â”€ evaluation_utils.py   # Evaluation metrics
â”‚
â””â”€â”€ config/                   # Configuration
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ settings.py           # Application settings
    â”œâ”€â”€ models_config.py      # Model configurations
    â””â”€â”€ workflows_config.py   # Workflow configurations
```

## ğŸ› ï¸ Installation

### Prerequisites
- Python 3.8+
- PostgreSQL 12+
- Qdrant Vector Database
- Redis (optional, for caching)

### Setup

1. **Clone the repository**
```bash
git clone <repository-url>
cd beetle_backend
```

2. **Install dependencies**
```bash
pip install -r requirements.txt
```

3. **Environment Configuration**
```bash
cp env.example .env
# Edit .env with your configuration
```

4. **Database Setup**
```bash
# PostgreSQL setup
createdb beetle_rag_db

# Qdrant setup (using Docker)
docker run -p 6333:6333 qdrant/qdrant
```

5. **Initialize the system**
```bash
python -m src.ai.setup
```

## âš™ï¸ Configuration

### Environment Variables

```env
# Database Configuration
DATABASE_URL=postgresql://user:password@localhost:5432/beetle_rag_db
QDRANT_URL=http://localhost:6333

# LLM Configuration
OPENAI_API_KEY=your_openai_key
ANTHROPIC_API_KEY=your_anthropic_key

# Redis Configuration (optional)
REDIS_URL=redis://localhost:6379

# Application Settings
APP_ENV=production
LOG_LEVEL=INFO
DEBUG=false
```

### Model Configuration

The system supports multiple LLM providers and embedding models:

```python
# LLM Models
- OpenAI: gpt-4, gpt-3.5-turbo
- Anthropic: claude-3-sonnet, claude-3-haiku
- Local: Custom models

# Embedding Models
- OpenAI: text-embedding-ada-002, text-embedding-3-small
- Sentence Transformers: all-MiniLM-L6-v2
- Code-specific: microsoft/codebert-base
```

## ğŸš€ Usage

### Basic RAG Query

```python
from src.ai.controllers.rag_controller import RAGController

# Initialize controller
rag_controller = RAGController()

# Process a query
result = await rag_controller.process_query(
    query="How do I implement authentication in FastAPI?",
    context_size=5,
    include_sources=True
)

print(result.answer)
print(result.sources)
```

### Document Ingestion

```python
from src.ai.agents.ingestion.file_ingestion_agent import FileIngestionAgent

# Initialize agent
ingestion_agent = FileIngestionAgent()

# Process documents
result = await ingestion_agent.process({
    "file_path": "/path/to/document.pdf",
    "metadata": {"source": "documentation", "category": "api"}
})
```

### Workflow Execution

```python
from src.ai.controllers.workflow_controller import WorkflowController

# Initialize controller
workflow_controller = WorkflowController()

# Execute RAG workflow
result = await workflow_controller.execute_workflow(
    workflow_id="rag_workflow_v1",
    input_data={
        "documents": ["doc1.pdf", "doc2.md"],
        "query": "Explain the authentication system"
    }
)
```

## ğŸ”§ API Endpoints

### RAG Operations

```http
POST /api/rag/query
POST /api/rag/ingest
POST /api/rag/process
GET /api/rag/status
```

### Workflow Management

```http
POST /api/workflows/execute
GET /api/workflows/list
GET /api/workflows/{workflow_id}
POST /api/workflows/create
```

### Agent Management

```http
GET /api/agents/status
POST /api/agents/execute
GET /api/agents/{agent_id}/health
```

### Monitoring

```http
GET /api/monitoring/metrics
GET /api/monitoring/health
GET /api/monitoring/alerts
```

## ğŸ“Š Monitoring & Evaluation

### Performance Metrics

The system tracks comprehensive metrics:

- **Retrieval Metrics**: Precision, Recall, F1-Score, MRR, NDCG
- **Generation Metrics**: BLEU, ROUGE, Relevance, Consistency
- **System Metrics**: CPU, Memory, Response Time
- **Custom Metrics**: User-defined performance indicators

### Evaluation Framework

```python
from src.ai.services.evaluation_service import get_evaluation_service

evaluation_service = get_evaluation_service()

# Evaluate single response
result = await evaluation_service.evaluate_rag_response(
    query="How to use FastAPI?",
    retrieved_docs=retrieved_documents,
    generated_answer="FastAPI is a modern web framework...",
    reference_answer="Reference answer here"
)

# Run benchmark
benchmark_result = await evaluation_service.run_benchmark(
    benchmark_name="fastapi_benchmark",
    test_queries=test_data,
    system_config=config
)
```

## ğŸ”’ Security Features

- **Authentication**: JWT-based authentication
- **Authorization**: Role-based access control
- **Input Validation**: Comprehensive input sanitization
- **Rate Limiting**: API rate limiting and throttling
- **Audit Logging**: Complete audit trail
- **Encryption**: Data encryption at rest and in transit

## ğŸš€ Deployment

### Docker Deployment

```dockerfile
FROM python:3.9-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .
EXPOSE 8000

CMD ["uvicorn", "src.ai.fastapi_server:app", "--host", "0.0.0.0", "--port", "8000"]
```

### Kubernetes Deployment

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: beetle-rag
spec:
  replicas: 3
  selector:
    matchLabels:
      app: beetle-rag
  template:
    metadata:
      labels:
        app: beetle-rag
    spec:
      containers:
      - name: beetle-rag
        image: beetle-rag:latest
        ports:
        - containerPort: 8000
        env:
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: db-secret
              key: url
```

## ğŸ§ª Testing

### Unit Tests

```bash
pytest tests/unit/
```

### Integration Tests

```bash
pytest tests/integration/
```

### Performance Tests

```bash
pytest tests/performance/
```

## ğŸ“ˆ Performance Optimization

### Caching Strategy

- **Query Cache**: Cache frequent queries
- **Embedding Cache**: Cache document embeddings
- **Result Cache**: Cache generated answers
- **Metadata Cache**: Cache document metadata

### Scaling Considerations

- **Horizontal Scaling**: Multiple instances
- **Load Balancing**: Distribute requests
- **Database Sharding**: Partition data
- **CDN Integration**: Static content delivery

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests
5. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ†˜ Support

- **Documentation**: [Wiki](link-to-wiki)
- **Issues**: [GitHub Issues](link-to-issues)
- **Discussions**: [GitHub Discussions](link-to-discussions)
- **Email**: support@beetle-rag.com

## ğŸ”„ Changelog

### v1.0.0 (2024-01-01)
- Initial release
- Core RAG functionality
- Agentic workflows
- Multi-LLM support
- Comprehensive monitoring
- Evaluation framework

---

**Built with â¤ï¸ by the Beetle Team** 